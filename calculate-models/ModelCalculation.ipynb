{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloudbutton geospatial use case: Model calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import json\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "import lithops\n",
    "from lithops.storage import Storage\n",
    "\n",
    "import numpy as np\n",
    "import pdal\n",
    "from osgeo import gdal\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BUCKET = 'cb-geospatial-wildfire'\n",
    "COMPUTE_BACKEND = 'localhost'\n",
    "STORAGE_BACKEND = 'localhost'\n",
    "STORAGE_PREFIX = 'localhost://'\n",
    "INPUT_DATA_PREFIX = 'input-las-tiles/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCC_WINDOW = 3\n",
    "FCC_BREAKPOINT = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Upload dataset\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_INPUT_DIR = 'input-las-tiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = Storage(backend=STORAGE_BACKEND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_objects = storage.list_keys(bucket=DATA_BUCKET)\n",
    "\n",
    "for file_name in os.listdir(LOCAL_INPUT_DIR):\n",
    "    if file_name not in bucket_objects:\n",
    "        key = os.path.join(INPUT_DATA_PREFIX, file_name)\n",
    "        with open(os.path.join(LOCAL_INPUT_DIR, file_name), 'rb') as file:\n",
    "            print(f'Uploading {key}...')\n",
    "            data = file.read()\n",
    "            storage.put_object(bucket=DATA_BUCKET, key=key, body=data)\n",
    "            print('Ok!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Calculte DEM, DSM and CHM\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.list_keys(bucket=DATA_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_models(obj, storage):\n",
    "    # Create temporary file paths\n",
    "    tmp_path_prefix = '/tmp/geo/'\n",
    "    if os.path.exists(tmp_path_prefix):\n",
    "        shutil.rmtree(tmp_path_prefix)\n",
    "    for subpath in ['dsm', 'dem', 'chm', 'aspect', 'slope', 'fcc']:\n",
    "        os.makedirs(os.path.join(tmp_path_prefix, subpath), exist_ok=True)\n",
    "\n",
    "    las_tile_filename = pathlib.Path(obj.key).name\n",
    "    tile_key = pathlib.Path(obj.key).stem\n",
    "\n",
    "    # Save obj to file\n",
    "    data = obj.data_stream.read()\n",
    "    input_file_path = os.path.join(tmp_path_prefix, las_tile_filename)\n",
    "    with open(input_file_path, 'wb') as file:\n",
    "        file.write(data)\n",
    "\n",
    "    # DSM pipeline\n",
    "    dsm_file_path = os.path.join(tmp_path_prefix, 'dsm', tile_key + '.gtiff')\n",
    "    dsm_pipeline_json = {\n",
    "        \"pipeline\": [\n",
    "            {\n",
    "                \"type\": \"readers.las\",\n",
    "                \"filename\": f\"{input_file_path}\",\n",
    "                \"spatialreference\": \"EPSG:25830\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.reprojection\",\n",
    "                \"in_srs\": \"EPSG:25830\",\n",
    "                \"out_srs\": \"EPSG:25830\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.outlier\",\n",
    "                \"method\": \"radius\",\n",
    "                \"radius\": 1.0,\n",
    "                \"min_k\": 4\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.range\",\n",
    "                # Classification equals 2 (corresponding to noise points in LAS).\n",
    "                \"limits\": \"Classification![7:7]\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.range\",\n",
    "                \"limits\": \"returnnumber[1:1]\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"writers.gdal\",\n",
    "                \"gdaldriver\": \"GTiff\",\n",
    "                \"nodata\": \"-9999\",\n",
    "                \"output_type\": \"max\",\n",
    "                \"resolution\": 1,\n",
    "                \"filename\": f\"{dsm_file_path}\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    dsm_pipeline_json_str = json.dumps(dsm_pipeline_json, indent=4)\n",
    "    pipeline = pdal.Pipeline(dsm_pipeline_json_str)\n",
    "    pipeline.validate()\n",
    "    pipeline.loglevel = 8\n",
    "    print('Executing DSM pipeline...')\n",
    "    result = pipeline.execute()\n",
    "    print(result)\n",
    "\n",
    "    # DEM pipeline\n",
    "    dem_file_path = os.path.join(tmp_path_prefix, 'dem', tile_key + '.gtiff')\n",
    "    dem_pipeline_json = {\n",
    "        \"pipeline\": [\n",
    "            {\n",
    "                \"type\": \"readers.las\",\n",
    "                \"filename\": f\"{input_file_path}\",\n",
    "                \"spatialreference\": \"EPSG:25830\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.reprojection\",\n",
    "                \"in_srs\": \"EPSG:25830\",\n",
    "                \"out_srs\": \"EPSG:25830\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.assign\",\n",
    "                \"assignment\": \"Classification[:]=0\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.elm\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.outlier\",\n",
    "                \"method\": \"radius\",\n",
    "                \"radius\": 1.0,\n",
    "                \"min_k\": 4\n",
    "            },\n",
    "            {\n",
    "\n",
    "                \"type\": \"filters.smrf\",\n",
    "                \"ignore\": \"Classification[7:7]\",\n",
    "                \"slope\": 0.2,\n",
    "                \"window\": 16,\n",
    "                \"threshold\": 0.45,\n",
    "                \"scalar\": 1.2\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"filters.range\",\n",
    "                # Classification equals 2 (corresponding to ground in LAS).\n",
    "                \"limits\": \"Classification[2:2]\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"writers.gdal\",\n",
    "                \"gdaldriver\": \"GTiff\",\n",
    "                \"nodata\": \"-9999\",\n",
    "                \"output_type\": \"max\",\n",
    "                \"resolution\": 1,\n",
    "                \"filename\": f\"{dem_file_path}\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    dem_pipeline_json_str = json.dumps(dem_pipeline_json, indent=4)\n",
    "    pipeline = pdal.Pipeline(dem_pipeline_json_str)\n",
    "    pipeline.validate()  # Check if json options are good\n",
    "    pipeline.loglevel = 8\n",
    "    print('Executing DEM pipeline...')\n",
    "    result = pipeline.execute()\n",
    "    print(result)\n",
    "\n",
    "    # calculate CHM\n",
    "    chm_file_path = os.path.join(tmp_path_prefix, 'chm', tile_key + '.tiff')\n",
    "    cmd = ['gdal_calc.py', '-A', dem_file_path, '-B', dsm_file_path,\n",
    "           '--calc=\"B-A\"', '--NoDataValue=0', '--outfile', chm_file_path]\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True)\n",
    "    stdout, stderr = p.communicate()\n",
    "    print(stdout, stderr)\n",
    "    # assert p.returncode == 0\n",
    "\n",
    "    # calculate aspect\n",
    "    aspect_file_path = os.path.join(tmp_path_prefix, 'aspect', tile_key + '.tiff')\n",
    "    cmd = ['gdaldem', 'aspect', dem_file_path, aspect_file_path, '-compute_edges']\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True)\n",
    "    stdout, stderr = p.communicate()\n",
    "    print(stdout, stderr)\n",
    "    # assert p.returncode == 0\n",
    "\n",
    "    # calculate slope\n",
    "    slope_file_path = os.path.join(tmp_path_prefix, 'slope', tile_key + '.tiff')\n",
    "    cmd = ['gdaldem', 'slope', dem_file_path, slope_file_path, '-compute_edges']\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True)\n",
    "    stdout, stderr = p.communicate()\n",
    "    print(stdout, stderr)\n",
    "    # assert p.returncode == 0\n",
    "\n",
    "    # calculate FCC\n",
    "    in_ds = gdal.Open(dem_file_path)\n",
    "    rows = in_ds.RasterYSize\n",
    "    cols = in_ds.RasterXSize\n",
    "    in_band = in_ds.GetRasterBand(1)\n",
    "    data = in_band.ReadAsArray(0, 0, cols, rows).astype(np.float)\n",
    "    data[data > FCC_BREAKPOINT] = 1\n",
    "    data[data <= FCC_BREAKPOINT] = 0\n",
    "\n",
    "    # Computing fraction on the whole raster through a moving window.\n",
    "    def _compute_fraction(array):\n",
    "        nveg = np.sum(array == 1)\n",
    "        total = len(array)\n",
    "        out = (nveg/total)*100\n",
    "        return(out)\n",
    "\n",
    "    TCC = ndimage.generic_filter(data, _compute_fraction, size=FCC_WINDOW)\n",
    "\n",
    "    gtiff_driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    fcc_file_path = os.path.join(tmp_path_prefix, 'fcc', tile_key + '.tiff')\n",
    "    out_ds = gtiff_driver.Create(fcc_file_path, cols, rows, 1, in_band.DataType)\n",
    "    out_ds.SetProjection(in_ds.GetProjection())\n",
    "    out_ds.SetGeoTransform(in_ds.GetGeoTransform())\n",
    "\n",
    "    out_band = out_ds.GetRasterBand(1)\n",
    "    out_band.WriteArray(TCC)\n",
    "    # out_ds.BuildOverviews(\"Average\", [2, 4, 8, 16, 32])\n",
    "    out_ds.FlushCache()\n",
    "    del in_ds, out_ds\n",
    "\n",
    "    outputs = [dsm_file_path, dem_file_path, chm_file_path,\n",
    "               aspect_file_path, slope_file_path, fcc_file_path]\n",
    "    for output_path in outputs:\n",
    "        if os.path.exists(output_path):\n",
    "            with open(output_path, 'rb') as output_file:\n",
    "                data = output_file.read()\n",
    "                cos_key = output_path.replace(tmp_path_prefix, '')\n",
    "                storage.put_object(bucket=DATA_BUCKET, key=cos_key, body=data)\n",
    "        else:\n",
    "            print(f'Failed to upload {output_path}')\n",
    "\n",
    "    out = subprocess.check_output(['find', '/tmp/geo/'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec = lithops.FunctionExecutor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(STORAGE_PREFIX, DATA_BUCKET, INPUT_DATA_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fexec.map(calculate_models, os.path.join(STORAGE_PREFIX, DATA_BUCKET, INPUT_DATA_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = fexec.get_result(fs=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in res:\n",
    "    print(r.decode('utf-8').strip())\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc28e218f8aa598d7201f1426aba0b64c29ddf364b0850b5108205e3c665e009"
  },
  "kernelspec": {
   "display_name": "cloudbutton-geospatial",
   "language": "python",
   "name": "cloudbutton-geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
