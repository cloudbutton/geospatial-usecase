{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cloudbutton Geospatial: Water Consumption Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T09:25:24.015057Z",
     "start_time": "2021-04-07T09:25:24.010199Z"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from cloudbutton_geospatial.io_utils.plot import plot_results\n",
    "from cloudbutton_geospatial.utils.notebook import date_picker\n",
    "from rasterio.windows import Window\n",
    "from scipy.spatial import distance_matrix\n",
    "from shapely.geometry import Point, MultiPoint, box\n",
    "from pprint import pprint\n",
    "import functools\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lithops\n",
    "import requests\n",
    "import rasterio\n",
    "import fiona\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import tempfile\n",
    "import concurrent.futures\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from lithops.storage import Storage\n",
    "from lithops.storage.utils import StorageNoSuchKeyError\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area outside the processed tile that we want to consider for taking SIAM stations into account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:28.795793Z",
     "start_time": "2021-04-13T14:38:28.788173Z"
    }
   },
   "outputs": [],
   "source": [
    "AREA_OF_INFLUENCE = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lithops Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:29.658886Z",
     "start_time": "2021-04-13T14:38:29.654251Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_BUCKET = 'cloudbutton-geospatial-wc'\n",
    "COMPUTE_BACKEND = 'aws_lambda'\n",
    "STORAGE_BACKEND = 'aws_s3'\n",
    "STORAGE_PREFIX = 's3://'\n",
    "RUNTIME = 'aitorarjona/cloudbutton-geospatial-wc:01'\n",
    "RUNTIME_MEMORY = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTM_PREFIX = 'DTMs/'\n",
    "DTM_ASC_PREFIX = 'DTMs/asc/'\n",
    "DTM_GEOTIFF_PREFIX = 'DTMs/geotiff/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split tile into square chunks (number of tiles = SPLITS^2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:30.525082Z",
     "start_time": "2021-04-13T14:38:30.519883Z"
    }
   },
   "outputs": [],
   "source": [
    "SPLITS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation coefficient between elevation and temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:31.362634Z",
     "start_time": "2021-04-13T14:38:31.359578Z"
    }
   },
   "outputs": [],
   "source": [
    "r = -0.0056"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elevation to interpolate temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:32.187402Z",
     "start_time": "2021-04-13T14:38:32.184798Z"
    }
   },
   "outputs": [],
   "source": [
    "zdet = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day of year to calculate solar irradiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedecaab8ac24af9ad35170d793299d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DatePicker(value=datetime.date(2022, 5, 15), description='Pick a Date')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date = date_picker(default=datetime.date(2022, 5, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:33.304420Z",
     "start_time": "2021-04-13T14:38:33.299098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAY_OF_YEAR = date.value.timetuple().tm_yday\n",
    "DAY_OF_YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Lithops Storage and Function Executor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:34.978991Z",
     "start_time": "2021-04-13T14:38:34.905888Z"
    }
   },
   "outputs": [],
   "source": [
    "storage = lithops.storage.Storage(backend=STORAGE_BACKEND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:43:44,803 [INFO] config.py:139 -- Lithops v3.1.0 - Python3.10\n",
      "2022-06-28 20:43:44,818 [INFO] aws_s3.py:68 -- S3 client created - Region: us-east-1\n",
      "2022-06-28 20:43:44,819 [INFO] aws_lambda.py:106 -- AWS Lambda client created - Region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "fexec = lithops.FunctionExecutor(backend=COMPUTE_BACKEND, storage=STORAGE_BACKEND, runtime=RUNTIME, runtime_memory=RUNTIME_MEMORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIAM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T09:46:49.948481Z",
     "start_time": "2021-04-07T09:46:49.800147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIAM meteo data already in storage: {'date': 'Tue, 28 Jun 2022 18:43:45 GMT', 'x-clv-request-id': 'c0268a02-dfae-4cf5-90d6-770e09f2b24e', 'server': 'Cleversafe', 'x-clv-s3-version': '2.5', 'accept-ranges': 'bytes', 'x-amz-request-id': 'c0268a02-dfae-4cf5-90d6-770e09f2b24e', 'etag': '\"8a1fd5da76b1123e66cc0155e6c8f5f7\"', 'content-type': 'text/csv', 'last-modified': 'Mon, 06 Jun 2022 08:53:34 GMT', 'content-length': '3850'}\n"
     ]
    }
   ],
   "source": [
    "siam_data_key = 'siam_data.csv'\n",
    "try:\n",
    "    siam_data_head = storage.head_object(bucket=DATA_BUCKET, key=siam_data_key)\n",
    "    print(f'SIAM meteo data already in storage: {siam_data_head}')\n",
    "except StorageNoSuchKeyError:\n",
    "    print('Uploading SIAM meteo data to Object Storage...')\n",
    "    with open(siam_data_key, 'rb') as f:\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=siam_data_key, body=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile already in storage: {'date': 'Tue, 28 Jun 2022 18:43:45 GMT', 'x-clv-request-id': 'c0268a02-dfae-4cf5-90d6-770e09f2b24e', 'server': 'Cleversafe', 'x-clv-s3-version': '2.5', 'accept-ranges': 'bytes', 'x-amz-request-id': 'c0268a02-dfae-4cf5-90d6-770e09f2b24e', 'etag': '\"8a1fd5da76b1123e66cc0155e6c8f5f7\"', 'content-type': 'text/csv', 'last-modified': 'Mon, 06 Jun 2022 08:53:34 GMT', 'content-length': '3850'}\n"
     ]
    }
   ],
   "source": [
    "shapefile_key = 'shapefile_murcia.zip'\n",
    "try:\n",
    "    shapefile_head = storage.head_object(bucket=DATA_BUCKET, key=shapefile_key)\n",
    "    print(f'Shapefile already in storage: {siam_data_head}')\n",
    "except StorageNoSuchKeyError:\n",
    "    print('Uploading shapefile to Object Storage...')\n",
    "    with open(shapefile_key, 'rb') as f:\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=shapefile_key, body=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital Terrain Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download DTM files for free from http://centrodedescargas.cnig.es/CentroDescargas/buscadorCatalogo.do?codFamilia=MDT05# and put them in `input_DTMs` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_asc_keys = storage.list_keys(bucket=DATA_BUCKET, prefix=DTM_ASC_PREFIX)\n",
    "# dtm_asc_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find downloaded MDTs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T09:48:12.000399Z",
     "start_time": "2021-04-07T09:48:11.986192Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_dtm_input = 'input_DTMs'\n",
    "local_dtms = [os.path.join(local_dtm_input, dtm) for dtm in os.listdir(local_dtm_input) if dtm.endswith('.asc')]\n",
    "\n",
    "def upload_file(file_path):\n",
    "    key = os.path.join(DTM_ASC_PREFIX, os.path.basename(file_path))\n",
    "    if key in dtm_asc_keys:\n",
    "        print(f'Tile {key} already in storage')\n",
    "        return key\n",
    "    with open(file_path, 'rb') as f:\n",
    "        print(f'Uploading {key}...')\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=key, body=f)\n",
    "    return key\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=16) as pool:\n",
    "    result = list(pool.map(upload_file, local_dtms))\n",
    "    # list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert ASCII raster files to Cloud Optimized GeoTIFF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asc_to_geotiff(obj, storage):\n",
    "    asc_file_name = os.path.basename(obj.key)\n",
    "    tile_id, _ = os.path.splitext(asc_file_name)\n",
    "    out_path = os.path.join(tempfile.gettempdir(), tile_id + '.tiff')\n",
    "    out_key = os.path.join(DTM_GEOTIFF_PREFIX, tile_id + '.tiff')\n",
    "\n",
    "    try:\n",
    "        out_obj = storage.head_object(bucket=DATA_BUCKET, key=out_key)\n",
    "    except StorageNoSuchKeyError:\n",
    "        out_obj = None\n",
    "\n",
    "    if out_obj:\n",
    "        print(f'GeoTIFF {tile_id} already exists, skipping...')\n",
    "        return out_key\n",
    "\n",
    "    print(f'Converting {tile_id} to GeoTIFF...')\n",
    "    with rasterio.open(obj.data_stream, 'r') as src:\n",
    "        profile = src.profile\n",
    "        # Cloud optimized GeoTiff parameters\n",
    "        profile.update(driver='GTiff')\n",
    "        profile.update(blockxsize=256)\n",
    "        profile.update(blockysize=256)\n",
    "        profile.update(tiled=True)\n",
    "        profile.update(compress='deflate')\n",
    "        profile.update(interleave='band')\n",
    "        with rasterio.open(out_path, 'w', **profile) as dest:\n",
    "            dest.write(src.read())\n",
    "\n",
    "    with open(out_path, 'rb') as f:\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=out_key, body=f)\n",
    "\n",
    "    return out_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:43:46,344 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M000 - Selected Runtime: aitorarjona/cloudbutton-geospatial-wc:01 - 2048MB\n",
      "2022-06-28 20:43:47,678 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M000 - Starting function invocation: asc_to_geotiff() - Total: 36 activations\n",
      "2022-06-28 20:43:47,742 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M000 - View execution logs at /tmp/lithops/logs/5449fa-0-M000.log\n"
     ]
    }
   ],
   "source": [
    "fs_cog = fexec.map(asc_to_geotiff, os.path.join(STORAGE_PREFIX, DATA_BUCKET, DTM_ASC_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:43:47,748 [INFO] lithops.wait -- ExecutorID 5449fa-0 - Waiting for 100% of 36 function activations to complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9693eea3290d4559a444a7a2f4bf5d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/36  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, _ = fexec.wait(fs=fs_cog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_geotiff_keys = storage.list_keys(bucket=DATA_BUCKET, prefix=DTM_GEOTIFF_PREFIX)\n",
    "# dtm_geotiff_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get bounds and tile ID for every tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_meta(obj):\n",
    "    storage = Storage()\n",
    "    tile_id = os.path.splitext(os.path.basename(obj.key))[0]\n",
    "    with rasterio.open(BytesIO(storage.get_cloudobject(obj)), 'r') as src:\n",
    "        x1, y1 = src.profile['transform'] * (0, 0)\n",
    "        x2, y2 = src.profile['transform'] * (src.profile['width'], src.profile['height'])\n",
    "    return tile_id, (x1, y1), (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:43:57,195 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M001 - Selected Runtime: aitorarjona/cloudbutton-geospatial-wc:01 - 2048MB\n",
      "2022-06-28 20:43:57,846 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M001 - Starting function invocation: get_tile_meta() - Total: 36 activations\n",
      "2022-06-28 20:43:57,847 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M001 - View execution logs at /tmp/lithops/logs/5449fa-0-M001.log\n"
     ]
    }
   ],
   "source": [
    "fs_meta = fexec.map(get_tile_meta, os.path.join(STORAGE_PREFIX, DATA_BUCKET, DTM_GEOTIFF_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:43:57,870 [INFO] lithops.wait -- ExecutorID 5449fa-0 - Getting results from 36 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1c4186f2554e7e8e019a75911592c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/36  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:44:11,032 [INFO] lithops.executors -- ExecutorID 5449fa-0 - Cleaning temporary data\n"
     ]
    }
   ],
   "source": [
    "tiles_meta = fexec.get_result(fs=fs_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiles_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69d7094cbf9485785a0a7add2228cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[38.082906, -1.330466], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyleaflet\n",
    "import ipywidgets\n",
    "import utm\n",
    "\n",
    "m = ipyleaflet.Map(center=(38.082906, -1.330466), zoom=9.5)\n",
    "\n",
    "for tile_id, bound1, bound2 in tiles_meta:\n",
    "    x1, y1 = bound1\n",
    "    x2, y2 = bound2\n",
    "    xc, yc = (x1 + x2) / 2, y1\n",
    "    \n",
    "    wgs_bounds_1 = utm.to_latlon(x1, y1, 30, 'S')\n",
    "    wgs_bounds_2 = utm.to_latlon(x2, y2, 30, 'S')\n",
    "    # wgs_bounds_c = utm.to_latlon(xc, yc, 30, 'S')\n",
    "\n",
    "    rectangle = ipyleaflet.Rectangle(bounds=(wgs_bounds_1, wgs_bounds_2))\n",
    "    m.add_layer(rectangle)    \n",
    "\n",
    "m.layout.height=\"750px\"\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster Data Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data tiles in subtiles for increased parallelism:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_chunker(obj, n_splits, block_x, block_y, storage):\n",
    "    tile_key = os.path.basename(obj.key)\n",
    "    tile_id, _ = os.path.splitext(tile_key)\n",
    "\n",
    "    storage = Storage()\n",
    "\n",
    "    with rasterio.open(BytesIO(storage.get_cloudobject(obj))) as src:\n",
    "        transform = src.transform\n",
    "\n",
    "        # Compute working window\n",
    "        step_w = src.width / n_splits\n",
    "        step_h = src.height / n_splits\n",
    "\n",
    "        offset_h = round(step_h * block_x)\n",
    "        offset_w = round(step_w * block_y)\n",
    "\n",
    "        profile = src.profile\n",
    "\n",
    "        width = math.ceil(step_w * (block_y + 1) - offset_w)\n",
    "        height = math.ceil(step_h * (block_x + 1) - offset_h)\n",
    "\n",
    "        profile.update(width=width)\n",
    "        profile.update(height=height)\n",
    "\n",
    "        window = Window(offset_w, offset_h, width, height)\n",
    "\n",
    "        chunk_file = os.path.join(tempfile.gettempdir(), tile_id + str(block_x) + '_' + str(block_y) + '.tif')\n",
    "        with rasterio.open(chunk_file, 'w', **profile) as dest:\n",
    "            dest.write(src.read(window=window))\n",
    "\n",
    "    with open(chunk_file, 'rb') as f:\n",
    "        co = storage.put_cloudobject(body=f, bucket=DATA_BUCKET)\n",
    "\n",
    "    return (tile_key, block_x, block_y, co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking 36 tiles in 9 chunks each using 324 functions\n"
     ]
    }
   ],
   "source": [
    "iterdata = [(os.path.join(STORAGE_PREFIX, DATA_BUCKET, tile), SPLITS, i, j)\n",
    "            for i in range(SPLITS) for j in range(SPLITS) for tile in dtm_geotiff_keys]\n",
    "print(f'Chunking {len(dtm_geotiff_keys)} tiles in {SPLITS * SPLITS} chunks each using {len(iterdata)} functions')\n",
    "# iterdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:44:11,250 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M002 - Selected Runtime: aitorarjona/cloudbutton-geospatial-wc:01 - 2048MB\n",
      "2022-06-28 20:44:11,813 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M002 - Starting function invocation: data_chunker() - Total: 324 activations\n",
      "2022-06-28 20:44:12,032 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M002 - View execution logs at /tmp/lithops/logs/5449fa-0-M002.log\n"
     ]
    }
   ],
   "source": [
    "chunker_fs = fexec.map(data_chunker, iterdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:44:12,043 [INFO] lithops.wait -- ExecutorID 5449fa-0 - Getting results from 324 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c6d79e04384f6c9329fda63265e01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/324  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:44:30,167 [INFO] lithops.executors -- ExecutorID 5449fa-0 - Cleaning temporary data\n"
     ]
    }
   ],
   "source": [
    "chunks = fexec.get_result(fs=chunker_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute solar irradiation for a given day of year using GRASS libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:54.462039Z",
     "start_time": "2021-04-13T14:38:54.449706Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_solar_irradiation(inputFile, outputFile, crs='32630'):\n",
    "    # Define grass working set\n",
    "    GRASS_GISDB = '/tmp/grassdata'\n",
    "    #GRASS_GISDB = 'grassdata'\n",
    "    GRASS_LOCATION = 'GEOPROCESSING'\n",
    "    GRASS_MAPSET = 'PERMANENT'\n",
    "    GRASS_ELEVATIONS_FILENAME = 'ELEVATIONS'\n",
    "\n",
    "    os.environ['GRASSBIN'] = 'grass76'\n",
    "\n",
    "    from grass_session import Session\n",
    "    import grass.script as gscript\n",
    "    import grass.script.setup as gsetup\n",
    "    from grass.pygrass.modules.shortcuts import general\n",
    "    from grass.pygrass.modules.shortcuts import raster\n",
    "    \n",
    "    os.environ.update(dict(GRASS_COMPRESS_NULLS='1'))\n",
    "\n",
    "    # Clean previously processed data\n",
    "    if os.path.isdir(GRASS_GISDB):\n",
    "        shutil.rmtree(GRASS_GISDB)\n",
    "    \n",
    "    with Session(gisdb=GRASS_GISDB, location=GRASS_LOCATION, mapset=GRASS_MAPSET, create_opts='EPSG:32630') as ses:\n",
    "        # Set project projection to match elevation raster projection\n",
    "        general.proj(epsg=crs, flags='c') \n",
    "        # Load raster file into working directory\n",
    "        raster.import_(input=inputFile, output=GRASS_ELEVATIONS_FILENAME, flags='o')    \n",
    "        \n",
    "        # Set project region to match raster region\n",
    "        general.region(raster=GRASS_ELEVATIONS_FILENAME, flags='s')    \n",
    "        # Calculate solar irradiation\n",
    "        gscript.run_command('r.slope.aspect', elevation=GRASS_ELEVATIONS_FILENAME,\n",
    "                            slope='slope', aspect='aspect')\n",
    "        gscript.run_command('r.sun', elevation=GRASS_ELEVATIONS_FILENAME,\n",
    "                            slope='slope', aspect='aspect', beam_rad='beam',\n",
    "                            step=1, day=DAY_OF_YEAR)\n",
    "        \n",
    "        # Get extraterrestrial irradiation from history metadata\n",
    "        regex = re.compile(r'\\d+\\.\\d+')\n",
    "        output = gscript.read_command(\"r.info\", flags=\"h\", map=[\"beam\"])\n",
    "        splits = str(output).split('\\n')\n",
    "        line = next(filter(lambda line: 'Extraterrestrial' in line, splits))\n",
    "        extraterrestrial_irradiance = float(regex.search(line)[0])\n",
    "        \n",
    "        # Export generated results into a GeoTiff file\n",
    "        if os.path.isfile(outputFile):\n",
    "            os.remove(outputFile)\n",
    "\n",
    "        raster.out_gdal(input='beam', output=outputFile)\n",
    "        \n",
    "        return extraterrestrial_irradiance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get stations contained in the area of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:55.461635Z",
     "start_time": "2021-04-13T14:38:55.457230Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_stations(bounds, stations):\n",
    "    total_points = MultiPoint([Point(x, y) for x, y in stations[['X', 'Y']].to_numpy()])\n",
    "    total_points_list = list(total_points.geoms)\n",
    "    intersection = bounds.buffer(AREA_OF_INFLUENCE).intersection(total_points)\n",
    "    filtered_stations = [point for point in total_points_list if intersection.contains(point)]\n",
    "\n",
    "    return stations[[point in filtered_stations for point in total_points_list]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Distance Weighting interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:58.209269Z",
     "start_time": "2021-04-13T14:38:58.202597Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_basic_interpolation(shape, stations, field_value, offset = (0,0)):\n",
    "    station_pixels = [[pixel[0], pixel[1]] for pixel in stations['pixel'].to_numpy()]\n",
    "    \n",
    "    # Get an array where each position represents pixel coordinates\n",
    "    tile_pixels = np.indices(shape).transpose(1,2,0).reshape(shape[0]*shape[1], 2) + offset\n",
    "    dist = distance_matrix(station_pixels, tile_pixels)\n",
    "    weights = np.where(dist == 0, np.finfo('float32').max, 1.0 / dist )\n",
    "    weights /=  weights.sum(axis=0)\n",
    "    \n",
    "    return np.dot(weights.T, stations[field_value].to_numpy()).reshape(shape).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate temperatures from a subset of the tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:38:59.031150Z",
     "start_time": "2021-04-13T14:38:59.005158Z"
    }
   },
   "outputs": [],
   "source": [
    "def radiation_interpolation(tile_key, block_x, block_y, chunk_cloudobject, storage):\n",
    "    tile_id, _ = os.path.splitext(tile_key)\n",
    "    print(tile_id)\n",
    "\n",
    "    # Write tile chunk to file\n",
    "    chunk_file = os.path.join(tempfile.gettempdir(), tile_id + str(block_x) + '_' + str(block_y) + '.tif')\n",
    "    print(chunk_file)\n",
    "\n",
    "    with open(chunk_file, 'wb') as f:\n",
    "        body = storage.get_cloudobject(chunk_cloudobject)\n",
    "        f.write(body)\n",
    "\n",
    "    with rasterio.open(chunk_file, 'r') as chunk_src:\n",
    "        profile = chunk_src.profile\n",
    "\n",
    "    extr_chunk_file = os.path.join(tempfile.gettempdir(), tile_id + '_extr_' + str(block_x) + '_' + str(block_y) + '.tif')\n",
    "    rad_chunk_file = os.path.join(tempfile.gettempdir(), tile_id + '_rad_' + str(block_x) + '_' + str(block_y) + '.tif')\n",
    "\n",
    "    # Compute solar irradiation from inputFile, creates radiation raster at outputFile\n",
    "    extraterrestrial_irradiation = compute_solar_irradiation(inputFile=chunk_file, outputFile=rad_chunk_file)\n",
    "\n",
    "    # Create and store a raster with extraterrestrial irradiation\n",
    "    with rasterio.open(extr_chunk_file, 'w', **profile) as dest:\n",
    "        data = np.full((profile['height'], profile['width']), extraterrestrial_irradiation, dtype='float32')\n",
    "        dest.write(data, 1)\n",
    "\n",
    "    with open(extr_chunk_file, 'rb') as f:\n",
    "        extr_co = storage.put_cloudobject(body=f, bucket=DATA_BUCKET)\n",
    "\n",
    "    with open(rad_chunk_file, 'rb') as f:\n",
    "        rad_co = storage.put_cloudobject(body=f, bucket=DATA_BUCKET)\n",
    "\n",
    "    return [(tile_key, 'extr', block_x, block_y, extr_co), (tile_key, 'rad', block_x, block_y, rad_co)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T14:39:01.538202Z",
     "start_time": "2021-04-13T14:39:01.521080Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_interpolation(tile_key, block_x, block_y, chunk_cloudobject, data_field, storage):\n",
    "    tile_id, _ = os.path.splitext(tile_key)\n",
    "\n",
    "    # Get SIAM meteo data\n",
    "    siam_stream = storage.get_object(DATA_BUCKET, siam_data_key, stream=True)\n",
    "    siam_data = pd.read_csv(siam_stream)\n",
    "\n",
    "    # print(siam_data)\n",
    "\n",
    "    chunk = storage.get_cloudobject(chunk_cloudobject)\n",
    "\n",
    "    with rasterio.open(BytesIO(chunk)) as chunk_src:\n",
    "        transform = chunk_src.transform\n",
    "        profile = chunk_src.profile\n",
    "\n",
    "        bounding_rect = box(chunk_src.bounds.left, chunk_src.bounds.top, chunk_src.bounds.right, chunk_src.bounds.bottom)\n",
    "        filtered = pd.DataFrame(filter_stations(bounding_rect, siam_data))\n",
    "        #print(filtered)\n",
    "\n",
    "        if filtered.shape[0] == 0:\n",
    "            return [(tile_key, data_field, block_x, block_y, None)]\n",
    "\n",
    "        filtered['pixel'] = filtered.apply(lambda station: rasterio.transform.rowcol(transform, station['X'], station['Y']), axis=1)\n",
    "\n",
    "        # Interpolate variables from meteo station data, generate raster with result\n",
    "        dest_chunk_file = os.path.join(tempfile.gettempdir(), tile_id + '_' + data_field + '_' + str(block_x) + '_' + str(block_y) + '.tif')\n",
    "\n",
    "        with rasterio.open(dest_chunk_file, 'w', **profile) as chunk_dest:\n",
    "            if data_field == 'temp':\n",
    "                elevations = chunk_src.read(1)  # Get elevations content\n",
    "                print(dest_chunk_file)\n",
    "                interpolation = compute_basic_interpolation(elevations.shape, filtered, 'tdet', (0, 0))\n",
    "                interpolation += r * (elevations - zdet)\n",
    "                chunk_dest.write(np.where(elevations == chunk_src.nodata, np.nan, interpolation), 1)\n",
    "            elif data_field == 'humi':\n",
    "                interpolation = compute_basic_interpolation((profile['height'], profile['width']), filtered, 'hr', (0, 0))\n",
    "                chunk_dest.write(interpolation, 1)\n",
    "            elif data_field == 'wind':\n",
    "                interpolation = compute_basic_interpolation((profile['height'], profile['width']), filtered, 'v', (0, 0))\n",
    "                chunk_dest.write(interpolation, 1)\n",
    "            else:\n",
    "                raise Exception(f'Unknown data field \"{data_field}\"')\n",
    "\n",
    "    # Upload results to storage as Cloudobject\n",
    "    with open(dest_chunk_file, 'rb') as f:\n",
    "        co = storage.put_cloudobject(body=f, bucket=DATA_BUCKET)\n",
    "\n",
    "    return [(tile_key, data_field, block_x, block_y, co)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lithops serverless computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T06:56:29.270356Z",
     "start_time": "2021-04-08T06:56:27.066344Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:44:30,294 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M003 - Selected Runtime: aitorarjona/cloudbutton-geospatial-wc:01 - 2048MB\n",
      "2022-06-28 20:44:30,827 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M003 - Starting function invocation: radiation_interpolation() - Total: 324 activations\n",
      "2022-06-28 20:44:30,839 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M003 - View execution logs at /tmp/lithops/logs/5449fa-0-M003.log\n",
      "2022-06-28 20:44:30,858 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M004 - Selected Runtime: aitorarjona/cloudbutton-geospatial-wc:01 - 2048MB\n",
      "2022-06-28 20:44:31,328 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M004 - Starting function invocation: map_interpolation() - Total: 324 activations\n",
      "2022-06-28 20:44:31,461 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M004 - View execution logs at /tmp/lithops/logs/5449fa-0-M004.log\n",
      "2022-06-28 20:44:31,464 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M005 - Selected Runtime: aitorarjona/cloudbutton-geospatial-wc:01 - 2048MB\n",
      "2022-06-28 20:44:31,682 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M005 - Starting function invocation: map_interpolation() - Total: 324 activations\n",
      "2022-06-28 20:44:31,687 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M005 - View execution logs at /tmp/lithops/logs/5449fa-0-M005.log\n",
      "2022-06-28 20:44:31,693 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M006 - Selected Runtime: aitorarjona/cloudbutton-geospatial-wc:01 - 2048MB\n",
      "2022-06-28 20:44:31,922 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M006 - Starting function invocation: map_interpolation() - Total: 324 activations\n",
      "2022-06-28 20:44:31,936 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M006 - View execution logs at /tmp/lithops/logs/5449fa-0-M006.log\n"
     ]
    }
   ],
   "source": [
    "fs_rad = fexec.map(radiation_interpolation, chunks, runtime_memory=2048)\n",
    "fs_temp = fexec.map(map_interpolation, chunks, extra_args=('temp', ), runtime_memory=2048)\n",
    "fs_humi = fexec.map(map_interpolation, chunks, extra_args=('humi', ), runtime_memory=2048)\n",
    "fs_wind = fexec.map(map_interpolation, chunks, extra_args=('wind', ), runtime_memory=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:44:32,036 [INFO] lithops.wait -- ExecutorID 5449fa-0 - Getting results from 324 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a790fa51a83e4f429327d8c54451db07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/324  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:53:26,101 [INFO] lithops.executors -- ExecutorID 5449fa-0 - Cleaning temporary data\n",
      "2022-06-28 20:53:26,148 [INFO] lithops.wait -- ExecutorID 5449fa-0 - Getting results from 324 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143227ab3bd846f8b32f4ad819db5410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/324  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:53:27,469 [INFO] lithops.executors -- ExecutorID 5449fa-0 - Cleaning temporary data\n",
      "2022-06-28 20:53:27,473 [INFO] lithops.wait -- ExecutorID 5449fa-0 - Getting results from 324 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243d30f7f26e446185f0c0f03a654e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/324  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:53:28,759 [INFO] lithops.executors -- ExecutorID 5449fa-0 - Cleaning temporary data\n",
      "2022-06-28 20:53:28,763 [INFO] lithops.wait -- ExecutorID 5449fa-0 - Getting results from 324 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f92007bf6e14c928609640a7afcf140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/324  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:53:30,185 [INFO] lithops.executors -- ExecutorID 5449fa-0 - Cleaning temporary data\n"
     ]
    }
   ],
   "source": [
    "res_rad = fexec.get_result(fs=fs_rad)\n",
    "res_temp = fexec.get_result(fs=fs_temp)\n",
    "res_humi = fexec.get_result(fs=fs_humi)\n",
    "res_wind = fexec.get_result(fs=fs_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_flatten = []\n",
    "for l in [res_rad, res_temp, res_humi, res_wind]:\n",
    "    for elem in l:\n",
    "        for sub_elem in elem:\n",
    "            res_flatten.append(sub_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_chunks = collections.defaultdict(list)\n",
    "\n",
    "for chunk_result in res_flatten:\n",
    "    tile_key, data_field, block_x, block_y, co = chunk_result\n",
    "    grouped_chunks[(tile_key, data_field)].append((block_x, block_y, co))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join split subsets into a tile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_blocks(tile_data, chunks, storage):\n",
    "    from rasterio.windows import Window\n",
    "\n",
    "    tile_key, data_field = tile_data\n",
    "\n",
    "    cobjs = [tup[2] for tup in chunks]\n",
    "    if None in cobjs:\n",
    "        return None\n",
    "\n",
    "    # Get width and height from original tile\n",
    "    source_tile_key = os.path.join(DTM_GEOTIFF_PREFIX, tile_key)\n",
    "    with rasterio.open(BytesIO(storage.get_object(bucket=DATA_BUCKET, key=source_tile_key))) as source_tile:\n",
    "        height = source_tile.profile['height']\n",
    "        width = source_tile.profile['width']\n",
    "\n",
    "    # Open first object to obtain profile metadata\n",
    "    with rasterio.open(BytesIO(storage.get_cloudobject(chunks[0][2]))) as chunk_src:\n",
    "        profile = chunk_src.profile\n",
    "        profile.update(width=width)\n",
    "        profile.update(height=height)\n",
    "\n",
    "    # Iterate each object and print its block into the destination file\n",
    "    merged_file = os.path.join(tempfile.gettempdir(), data_field + '_' + tile_key)\n",
    "    with rasterio.open(merged_file, 'w', **profile) as dest:\n",
    "        for chunk in chunks:\n",
    "            j, i, co = chunk\n",
    "            with rasterio.open(BytesIO(storage.get_cloudobject(co))) as src:\n",
    "                step_w = math.floor(width / SPLITS)\n",
    "                step_h = math.floor(height / SPLITS)\n",
    "                curr_window = Window(round(step_w * i), round(step_h * j), src.width, src.height)\n",
    "                content = src.read(1)\n",
    "                dest.write(content, 1, window=curr_window)\n",
    "\n",
    "    output_key = os.path.join(DTM_PREFIX, data_field, tile_key)\n",
    "    with open(merged_file, 'rb') as out_file:\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=output_key, body=out_file)\n",
    "\n",
    "    return output_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine previous split subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterdata = []\n",
    "for (tile_id, data_field), chunks in grouped_chunks.items():\n",
    "    iterdata.append(((tile_id, data_field), chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:53:30,284 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M007 - Selected Runtime: aitorarjona/cloudbutton-geospatial-wc:01 - 2048MB\n",
      "2022-06-28 20:53:30,617 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M007 - Starting function invocation: merge_blocks() - Total: 180 activations\n",
      "2022-06-28 20:53:30,619 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M007 - View execution logs at /tmp/lithops/logs/5449fa-0-M007.log\n"
     ]
    }
   ],
   "source": [
    "fs_merged = fexec.map(merge_blocks, iterdata, runtime_memory=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:53:30,644 [INFO] lithops.wait -- ExecutorID 5449fa-0 - Getting results from 180 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d614d4754154d1badf66d8ce53dee14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/180  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:54:26,437 [INFO] lithops.executors -- ExecutorID 5449fa-0 - Cleaning temporary data\n"
     ]
    }
   ],
   "source": [
    "tiles_merged = fexec.get_result(fs=fs_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_keys_merged = set([os.path.basename(t) for t in tiles_merged])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile_keys_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of potential evaporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:51.493674Z",
     "start_time": "2021-04-13T16:57:51.485032Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_crop_evapotranspiration(temperatures,\n",
    "                                    humidities,\n",
    "                                    wind_speeds,\n",
    "                                    external_radiations,\n",
    "                                    global_radiations,\n",
    "                                    KCs):\n",
    "    gamma = 0.665*101.3/1000\n",
    "    eSat = 0.6108 * np.exp((17.27*temperatures)/(temperatures+237.3))\n",
    "    delta = 4098 * eSat / np.power((temperatures + 237.3),2)\n",
    "    eA = np.where(humidities < 0, 0, eSat * humidities / 100)     # Avoid sqrt of a negative number\n",
    "    T4 = 4.903 * np.power((273.3 + temperatures),4)/1000000000\n",
    "    rSrS0 = global_radiations/(external_radiations * 0.75)\n",
    "    rN = 0.8* global_radiations-T4*(0.34-0.14*np.sqrt(eA))*((1.35*rSrS0)-0.35)\n",
    "    den = delta + gamma *(1 + 0.34* wind_speeds)\n",
    "    tRad = 0.408 * delta * rN / den\n",
    "    tAdv = gamma * (900/(temperatures+273))*wind_speeds * (eSat - eA)/den\n",
    "    return ((tRad + tAdv) * 7 * KCs).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:52.760441Z",
     "start_time": "2021-04-13T16:57:52.753812Z"
    }
   },
   "outputs": [],
   "source": [
    "vineyard = ['VI', 'VO', 'VF', 'FV', 'CV' ]\n",
    "olive_grove = ['OV', 'VO', 'OF', 'FL', 'OC']\n",
    "fruit = ['FY', 'VF', 'OF', 'FF', 'CF']\n",
    "nuts = ['FS', 'FV', 'FL', 'FF', 'CS' ]\n",
    "citrus = ['CI', 'CV', 'OC', 'CF', 'CS' ]\n",
    "\n",
    "def get_kc(feature):\n",
    "    # TODO: Get more precise values of Kc\n",
    "    print(feature['properties'].keys())\n",
    "    # sigpac_use = feature['properties']['uso_sigpac']\n",
    "    sigpac_use = 'FF'\n",
    "    if sigpac_use in vineyard:\n",
    "        # Grapes for wine - 0.3, 0.7, 0.45\n",
    "        return 0.7  \n",
    "    if sigpac_use in olive_grove:\n",
    "        # Olive grove - ini: 0.65, med: 0.7, end: 0.7\n",
    "        return 0.7 \n",
    "    if sigpac_use in fruit:\n",
    "        # Apples, Cherries, Pears - 0.45, 0.95, 0.7\n",
    "        return 0.95\n",
    "    if sigpac_use in nuts:\n",
    "        # Almonds - 0.4, 0.9, 0.65\n",
    "        return 0.9\n",
    "    if sigpac_use in citrus:\n",
    "        # Citrus, without ground coverage - 0.7, 0.65, 0.7\n",
    "        return 0.65\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:54.250115Z",
     "start_time": "2021-04-13T16:57:54.243932Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_geometry_window(src, geom_bounds):\n",
    "    left, bottom, right, top = geom_bounds\n",
    "    src_left, src_bottom, src_right, src_top = src.bounds\n",
    "    window = src.window(max(left,src_left), max(bottom,src_bottom), min(right,src_right), min(top,src_top))\n",
    "    window_floored = window.round_offsets(op='floor', pixel_precision=3)\n",
    "    w = math.ceil(window.width + window.col_off - window_floored.col_off)\n",
    "    h = math.ceil(window.height + window.row_off - window_floored.row_off)\n",
    "    return Window(window_floored.col_off, window_floored.row_off, w, h)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:57.781920Z",
     "start_time": "2021-04-13T16:57:57.770029Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_evapotranspiration_by_shape(tem, hum, win, rad, extrad, dst):\n",
    "\n",
    "    import fiona\n",
    "    from shapely.geometry import shape, box\n",
    "    from rasterio import features\n",
    "\n",
    "    non_arable_land = ['AG', 'CA', 'ED', 'FO', 'IM', 'PA', 'PR', 'ZU', 'ZV']\n",
    "\n",
    "    #with fiona.open('zip://home/docker/shape.zip') as shape_src:\n",
    "    with fiona.open('zip:///tmp/shape.zip') as shape_src:\n",
    "        for feature in shape_src.filter(bbox=tem.bounds):\n",
    "            KC = get_kc(feature)\n",
    "            if KC is not None:\n",
    "                geom = shape(feature['geometry'])\n",
    "                window = get_geometry_window(tem, geom.bounds)\n",
    "                win_transform = rasterio.windows.transform(window, tem.transform)\n",
    "                # Convert shape to raster matrix\n",
    "                image = features.rasterize([geom],\n",
    "                                           out_shape=(window.height, window.width),\n",
    "                                           transform = win_transform,\n",
    "                                           fill = 0,\n",
    "                                           default_value = 1).astype('bool')\n",
    "                # Get values to compute evapotranspiration\n",
    "                temperatures = tem.read(1, window=window)\n",
    "                humidities = hum.read(1, window=window)\n",
    "                wind_speeds = win.read(1, window=window)\n",
    "                # Convert from W to MJ (0.0036)\n",
    "                global_radiations = rad.read(1, window=window) * 0.0036\n",
    "                external_radiations = extrad.read(1, window=window) * 0.0036\n",
    "                KCs = np.full(temperatures.shape, KC)\n",
    "                # TODO: compute external radiation\n",
    "                #external_radiations = np.full(temperatures.shape, 14)\n",
    "                # TODO: compute global radiation\n",
    "                # global_radiations = np.full(temperatures.shape, 10)\n",
    "                etc = compute_crop_evapotranspiration(\n",
    "                        temperatures,\n",
    "                        humidities,\n",
    "                        wind_speeds,\n",
    "                        external_radiations,\n",
    "                        global_radiations,\n",
    "                        KCs\n",
    "                )\n",
    "                etc[temperatures == tem.nodata] = dst.nodata\n",
    "                etc[np.logical_not(image)] = dst.nodata\n",
    "                dst.write(etc + dst.read(1, window=window), 1, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:57:59.216824Z",
     "start_time": "2021-04-13T16:57:59.207435Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_global_evapotranspiration(tem, hum, win, rad, extrad, dst):    \n",
    "    for ji, window in tem.block_windows(1):\n",
    "        bounds = rasterio.windows.bounds(window, tem.transform)\n",
    "        temperatures = tem.read(1, window=window)\n",
    "        humidities = hum.read(1, window=window)\n",
    "        wind_speeds = win.read(1, window=window)\n",
    "         # Convert from W to MJ (0.0036)\n",
    "        global_radiations = rad.read(1, window=window) * 0.0036\n",
    "        external_radiations = extrad.read(1, window=window) * 0.0036\n",
    "        # TODO: compute external radiation\n",
    "        #external_radiations = np.full(temperatures.shape, 14)\n",
    "        # TODO: compute global radiation\n",
    "        # global_radiations = np.full(temperatures.shape, 10)\n",
    "        # TODO: compute KCs\n",
    "        KCs = np.full(temperatures.shape, 1)\n",
    "        etc = compute_crop_evapotranspiration(\n",
    "                temperatures,\n",
    "                humidities,\n",
    "                wind_speeds,\n",
    "                external_radiations,\n",
    "                global_radiations,\n",
    "                KCs\n",
    "        )\n",
    "        dst.write(np.where(temperatures == tem.nodata, dst.nodata, etc), 1, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:58:01.128416Z",
     "start_time": "2021-04-13T16:58:01.101842Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_calculations(tile_key, storage):\n",
    "    from functools import partial\n",
    "      \n",
    "    # Download shapefile\n",
    "    shapefile = storage.get_object(bucket=DATA_BUCKET, key='shapefile_murcia.zip', stream=True)\n",
    "\n",
    "    with open('/tmp/shape.zip', 'wb') as shapf:\n",
    "        for chunk in iter(partial(shapefile.read, 200 * 1024 * 1024), ''):\n",
    "            if not chunk:\n",
    "                break\n",
    "            shapf.write(chunk)\n",
    "    try:\n",
    "        temp = storage.get_object(bucket=DATA_BUCKET, key=os.path.join(DTM_PREFIX, 'temp', tile_key))\n",
    "        humi = storage.get_object(bucket=DATA_BUCKET, key=os.path.join(DTM_PREFIX, 'humi', tile_key))\n",
    "        rad = storage.get_object(bucket=DATA_BUCKET, key=os.path.join(DTM_PREFIX, 'rad', tile_key))\n",
    "        extrad = storage.get_object(bucket=DATA_BUCKET, key=os.path.join(DTM_PREFIX, 'extr', tile_key))\n",
    "        wind = storage.get_object(bucket=DATA_BUCKET, key=os.path.join(DTM_PREFIX, 'wind', tile_key))\n",
    "    except StorageNoSuchKeyError:\n",
    "        print(\"Storage error\")\n",
    "        return None\n",
    "    \n",
    "    output_file = os.path.join(tempfile.gettempdir(), 'eva' + '_' + tile_key)\n",
    "    with rasterio.open(BytesIO(temp)) as temp_raster:\n",
    "        with rasterio.open(BytesIO(humi)) as humi_raster:\n",
    "            with rasterio.open(BytesIO(rad)) as rad_raster:\n",
    "                with rasterio.open(BytesIO(extrad)) as extrad_raster:\n",
    "                    with rasterio.open(BytesIO(wind)) as wind_raster:\n",
    "                        profile = temp_raster.profile\n",
    "                        profile.update(nodata=0)\n",
    "                        with rasterio.open(output_file, 'w+', **profile) as dst:\n",
    "#                             compute_global_evapotranspiration(temp_raster, humi_raster, wind_raster,\n",
    "#                                                               rad_raster, extrad_raster, dst)\n",
    "                            compute_evapotranspiration_by_shape(temp_raster, humi_raster, wind_raster,\n",
    "                                                                rad_raster, extrad_raster, dst)\n",
    "    \n",
    "    output_key = os.path.join(DTM_PREFIX, 'eva', tile_key)\n",
    "    with open(output_file, 'rb') as output_f:\n",
    "        storage.put_object(bucket=DATA_BUCKET, key=output_key, body=output_f)\n",
    "    return output_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T16:58:55.822484Z",
     "start_time": "2021-04-13T16:58:54.943303Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:54:26,530 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M008 - Selected Runtime: aitorarjona/cloudbutton-geospatial-wc:01 - 2048MB\n",
      "2022-06-28 20:54:26,881 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M008 - Starting function invocation: combine_calculations() - Total: 36 activations\n",
      "2022-06-28 20:54:26,883 [INFO] lithops.invokers -- ExecutorID 5449fa-0 | JobID M008 - View execution logs at /tmp/lithops/logs/5449fa-0-M008.log\n",
      "2022-06-28 20:54:26,899 [INFO] lithops.wait -- ExecutorID 5449fa-0 - Getting results from 36 function activations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8bad64cdd14d69badb812105efa4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "    0%|          | 0/36  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:55:09,305 [INFO] lithops.executors -- ExecutorID 5449fa-0 - Cleaning temporary data\n"
     ]
    }
   ],
   "source": [
    "fs_eva = fexec.map(combine_calculations, tile_keys_merged, runtime_memory=2048)\n",
    "res_eva = fexec.get_result(fs=fs_eva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DTMs/eva/PNOA_MDT05_ETRS89_HU30_0976_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0891_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0931_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0975_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0932_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0870_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0935_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0911_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0934_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0955_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0978_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0977_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0997_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0956_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0910_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0997B_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0933_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0890_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0912_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0845_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0869_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0913_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0953_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0819_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0954_LID.tiff',\n",
       " 'DTMs/eva/PNOA_MDT05_ETRS89_HU30_0892_LID.tiff']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_eva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 20:55:09,549 [INFO] lithops.executors -- ExecutorID 5449fa-0 - Creating execution plots\n"
     ]
    }
   ],
   "source": [
    "fexec.plot(dst=fexec.executor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec.clean(clean_cloudobjects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 21:00:39,924 [INFO] lithops.executors -- View log file logs at /tmp/lithops/logs/2022-06-28_21:00:39.csv\n"
     ]
    }
   ],
   "source": [
    "fexec.job_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dtm_asc_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sz = 0\n",
    "for input_key in dtm_asc_keys:\n",
    "    meta = storage.head_object(bucket=DATA_BUCKET, key=input_key)\n",
    "    input_sz += int(meta['content-length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6071113373"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T21:32:01.429761Z",
     "start_time": "2021-04-13T21:32:00.245568Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "with rasterio.open('PNOA_MDT05_ETRS89_HU30_0891_LID.tiff') as src:\n",
    "    arr = src.read(1, out_shape=(src.height, src.width))\n",
    "    ax.set_title(tile_id)\n",
    "    img = ax.imshow(arr, cmap='Greens')\n",
    "    fig.colorbar(img, shrink=0.5)\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n",
    "# obj.seek(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
