{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDVI Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import lithops\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import gc\n",
    "import datetime\n",
    "import math\n",
    "import collections\n",
    "from rasterio.io import MemoryFile\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "\n",
    "import cloudbutton_geospatial.s2froms3 as s2froms3\n",
    "from cloudbutton_geospatial.utils import notebook as notebook_utils\n",
    "from cloudbutton_geospatial.io_utils.ndvi import get_ndvi_params, ndvi_calculation, ndvi_tile_sentinel, get_subset_raster, lonlat_to_utm, get_poly_within\n",
    "from cloudbutton_geospatial.io_utils.plot import tiff_overview, plot_map\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the date interval in which tiles will be processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_from = datetime.date(year=2019, month=9, day=17)\n",
    "default_to = datetime.date(year=2020, month=9, day=16)\n",
    "\n",
    "from_date, to_date = notebook_utils.pick_date_range(default_from, default_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the tile's cloud percentage threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = notebook_utils.pick_percentage_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the area which delimites the tiles you want to process (left click to mark a point in the map, right click to erase current selection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_region = notebook_utils.MapRegion(center=(39.60595289727246, -122.82804126978336))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = []\n",
    "lats = []\n",
    "lons = []\n",
    "points = []\n",
    "\n",
    "for value in map_region.get_region()[:-1]:\n",
    "    coords.append(value)\n",
    "    lats.append(value[1])\n",
    "    lons.append(value[0])\n",
    "\n",
    "start_date = from_date.value  # Start date to search images\n",
    "end_date = to_date.value  # End date to search images\n",
    "what = ['B04', 'B08']  # What we want to download\n",
    "cc = percentage.value  # Minimum cloud cover on each image, 25 is 25%\n",
    "\n",
    "for lon, lat in zip(lons, lats):\n",
    "    points.append([lon, lat])\n",
    "    print([lon, lat], start_date, end_date, what, cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def distance(origin, destination):\n",
    "    lat1, lon1 = origin\n",
    "    lat2, lon2 = destination\n",
    "    radius = 6371  # km\n",
    "\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = (math.sin(dlat / 2) * math.sin(dlat / 2) +\n",
    "         math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) *\n",
    "         math.sin(dlon / 2) * math.sin(dlon / 2))\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, p = 0, 0\n",
    "\n",
    "while i != len(points):\n",
    "    p = i + 1\n",
    "    while p != len(points):\n",
    "        dis = distance(points[i], points[p])\n",
    "        divisions = int(dis / 100)\n",
    "        # If the zones are separated by more than 100 km, generate intermediate zones\n",
    "        if divisions > 0:\n",
    "            toSum = [(points[i][0] - points[p][0]) / (divisions + 1) , (points[i][1] - points[p][1]) / (divisions + 1)]\n",
    "            while divisions != 0:\n",
    "                point = points[i][0] - (toSum[0] * divisions)\n",
    "                # Not add duplicated lons/lats\n",
    "                if point not in lons:\n",
    "                    lons.append(points[i][0] - (toSum[0] * divisions))\n",
    "                    lats.append(points[i][1] - (toSum[1] * divisions))\n",
    "                divisions = divisions - 1\n",
    "        p = p + 1 \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = from_date.value  # Start date to search images\n",
    "end_date = to_date.value  # End date to search images\n",
    "what = ['B04', 'B08']  # What we want to download\n",
    "cc = percentage.value  # Minimum cloud cover on each image, 25 is 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Californa tile coords\n",
    "cali_coords = [\n",
    "    [38.510161585585045, -122.99194335937501],\n",
    "    [36.071996052851325, -121.25610351562501],\n",
    "    [36.96374622851412, -121.46484375000001],\n",
    "    [37.575739257598414, -121.55273437500001],\n",
    "    [39.15202827678992, -122.62939453125001],\n",
    "    [39.703620879017976, -123.12377929687501],\n",
    "    [36.74397383313428, -119.94873046875001],\n",
    "    [38.472809653752314, -121.60766601562501]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sentinel-2 packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scenes_f1 = []\n",
    "scenes_f2 = []\n",
    "\n",
    "for longitude, latency in zip(lons, lats):\n",
    "    try:\n",
    "        # Get scenes from intital date\n",
    "        f1 = s2froms3.get_scene_list(lon=longitude, lat=latency, start_date=start_date, end_date=start_date,\n",
    "        what=what, cloud_cover_le=cc)\n",
    "\n",
    "        # Get scenes from end date\n",
    "        f2 = s2froms3.get_scene_list(lon=longitude, lat=latency, start_date=end_date, end_date=end_date,\n",
    "        what=what, cloud_cover_le=cc)\n",
    "\n",
    "        # Not add duplicated scenes\n",
    "        if len(scenes_f1) == 0 or f1 not in scenes_f1:\n",
    "            scenes_f1.append(f1)\n",
    "            scenes_f2.append(f2)\n",
    "\n",
    "            print(f'Found scenes {start_date}:', f1)\n",
    "            print(f'Found scenes {end_date}:', f2)\n",
    "            print(f'Lon: {longitude}, Lat: {latency}')\n",
    "            print(f'Cell: {f1[0][0].split(\"/\")[2]} {f1[0][0].split(\"/\")[3]} {f1[0][0].split(\"/\")[4]}\\n')\n",
    "    \n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "if len(scenes_f1) == 0:\n",
    "    raise Exception('No data found')\n",
    "\n",
    "scene = scenes_f1[-1][-1]\n",
    "scene_band = rasterio.open('s3://'+scene[0])\n",
    "windows = list(scene_band.block_windows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_band_keys = [tup[0] for tup in scenes_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec = lithops.FunctionExecutor(\n",
    "        backend='aws_lambda',\n",
    "        storage='aws_s3',\n",
    "        log_level='INFO',\n",
    "        runtime_memory=1024,\n",
    "        runtime='aitorarjona/cloudbutton-ndvi:01'  # Runtime for AWS Lambda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_meta(key):\n",
    "    with rasterio.open('s3://'+key) as src:\n",
    "        x1, y1 = src.profile['transform'] * (0, 0)\n",
    "        x2, y2 = src.profile['transform'] * (src.profile['width'], src.profile['height'])\n",
    "    return key, (x1, y1), (x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_meta = fexec.map(get_tile_meta, tile_band_keys)\n",
    "tiles_meta = fexec.get_result(fs=fs_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiles_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [(tile_id, bound1, bound2,\n",
    "            int(tile_id.split('/')[7].split('_')[1][:2]),\n",
    "            True) for tile_id, bound1, bound2 in tiles_meta]\n",
    "notebook_utils.show_map_regions(regions=regions, center=(38.141080, -122.126583), zoom=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndvi(scene, ij_window, storage):\n",
    "    ij, window = ij_window\n",
    "    band_4_s3_loc, band_8_s3_loc = scene\n",
    "    band_path = band_4_s3_loc.split('/')\n",
    "    ndvi_local = f'/tmp/{band_path[7]}_{ij}_NDVI.tif'\n",
    "    jpg_local = f'/tmp/{band_path[7]}_{ij}_NDVI.jpg'\n",
    "\n",
    "    # generate nir and red objects as arrays in float64 format\n",
    "    band4 = rasterio.open('s3://'+band_4_s3_loc)  # red\n",
    "    band8 = rasterio.open('s3://'+band_8_s3_loc)  # nir\n",
    "\n",
    "    profile = band4.profile\n",
    "    profile.update(dtype='float64')\n",
    "    profile.update(width=window.width)\n",
    "    profile.update(height=window.height)\n",
    "\n",
    "    with rasterio.open(ndvi_local, 'w', **profile) as dst:\n",
    "        red = band4.read(1, window=window).astype('float64')\n",
    "        nir = band8.read(1, window=window).astype('float64')\n",
    "        ndvi = (np.where((nir + red) == 0., 0, (nir - red) / (nir + red))).astype('float64')\n",
    "        ndvi_mean = np.mean(ndvi, axis=0)\n",
    "        dst.write(ndvi, 1)\n",
    "        ndvi[0][0] = -1\n",
    "        ndvi[0][1] = 1\n",
    "        plt.imsave(jpg_local, ndvi, cmap=\"RdYlGn\")\n",
    "\n",
    "    with open(jpg_local, 'rb') as jpg_temp:\n",
    "        co_jpg = storage.put_cloudobject(jpg_temp.read(), key=jpg_local.replace('/tmp/', ''))\n",
    "\n",
    "    return ndvi_local, ndvi_mean, co_jpg\n",
    "\n",
    "\n",
    "def compute_ndvi_diff(old_scene, new_scene, ij_window, storage):\n",
    "    ij, window = ij_window\n",
    "    band_path = new_scene[0].split('/')\n",
    "    jpg_diff_local = f'/tmp/{band_path[7]}_{ij}_NDVI_DIFF.jpg'\n",
    "    key = old_scene[0].split('/')[7].rsplit('_', 3)[0]\n",
    "\n",
    "    ndvi_local_f1, ndvi_mean_f1, co_jpg_f1 = calculate_ndvi(old_scene, ij_window, storage)\n",
    "    ndvi_local_f2, ndvi_mean_f2, co_jpg_f2 = calculate_ndvi(new_scene, ij_window, storage)\n",
    "\n",
    "    ndvi_old = rasterio.open(ndvi_local_f1)\n",
    "    ndvi_new = rasterio.open(ndvi_local_f2)\n",
    "\n",
    "    profile = ndvi_old.profile\n",
    "    profile.update(dtype='float64')\n",
    "    profile.update(width=window.width)\n",
    "    profile.update(height=window.height)\n",
    "\n",
    "    no = ndvi_old.read(1).astype('float64')\n",
    "    nn = ndvi_new.read(1).astype('float64')\n",
    "    ndvi_cmp = ((nn - no) * (nn + no)).astype('float64')\n",
    "    ndvi_cmp[0][0] = -1\n",
    "    ndvi_cmp[0][1] = 1\n",
    "    plt.imsave(jpg_diff_local, ndvi_cmp, cmap=\"RdYlGn\")\n",
    "\n",
    "    with open(jpg_diff_local, 'rb') as jpg_diff_file:\n",
    "        co_jpg_diff = storage.put_cloudobject(jpg_diff_file, key=jpg_diff_local.replace('/tmp/', ''))\n",
    "\n",
    "    return key, ij_window, co_jpg_f1, co_jpg_f2, co_jpg_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the selected parameters, get the identifiers of the selected tiles from Sentinel-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec = lithops.FunctionExecutor(\n",
    "        backend='aws_lambda',\n",
    "        storage='aws_s3',\n",
    "        log_level='INFO',\n",
    "        runtime_memory=1024,\n",
    "        runtime='aitorarjona/cloudbutton-ndvi:01'  # Runtime for AWS Lambda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterdata = []\n",
    "for scene_f1, scene_f2 in zip(scenes_f1, scenes_f2):\n",
    "    for wd in windows:\n",
    "        iterdata.append((scene_f1[0], scene_f2[0], wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs = fexec.map(compute_ndvi_diff, iterdata)\n",
    "results = fexec.get_result(fs=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_results = collections.defaultdict(list)\n",
    "\n",
    "for res in results:\n",
    "    key, ij_window, co_jpg_f1, co_jpg_f2, co_jpg_diff = res\n",
    "    grouped_results[key].append((ij_window, co_jpg_f1, co_jpg_f2, co_jpg_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and plot the computed jpg diff tile image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_jpg(data):\n",
    "    file = '_'.join(data[0][1].key.split('_')[:5])\n",
    "    \n",
    "    if 'DIFF' in data[0][1].key:\n",
    "        out_file = f'AwsData/{file}_NDVI_DIFF.jpg'\n",
    "    else:\n",
    "        out_file = f'AwsData/{file}_NDVI.jpg'\n",
    "        \n",
    "    jpgs = {}\n",
    "\n",
    "    def get_window(data):\n",
    "        ij_window, co_jpg = data\n",
    "        row = ij_window[0][0]\n",
    "        col = ij_window[0][1]\n",
    "        jpg_stream = fexec.storage.get_cloudobject(co_jpg, stream=True)\n",
    "\n",
    "        if row not in jpgs:\n",
    "            jpgs[row] = [None]*11\n",
    "\n",
    "        jpgs[row][col] = Image.open(jpg_stream)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=16) as ex:\n",
    "        fs = list(ex.map(get_window, data))\n",
    "\n",
    "    new_im = Image.new('RGB', (scene_band.width, scene_band.height))\n",
    "\n",
    "    x_offset = 0\n",
    "    y_offset = 0\n",
    "\n",
    "    for row in sorted(jpgs.keys()):\n",
    "        for im in jpgs[row]:\n",
    "            new_im.paste(im, (x_offset, y_offset))\n",
    "            x_offset += im.size[0]\n",
    "        x_offset = 0\n",
    "        y_offset += im.size[1]\n",
    "        \n",
    "    thumbnail_zise = (640, 640)\n",
    "    new_im.thumbnail(thumbnail_zise)\n",
    "\n",
    "    # fig = plt.figure(figsize=(10, 10))\n",
    "    # plt.title(out_file)\n",
    "    # plt.imshow(new_im)\n",
    "    images[out_file] = new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_jpgs_f1 = [(res[0], res[1]) for res in grouped_results['S2A_10SEJ']]\n",
    "co_jpgs_f2 = [(res[0], res[2]) for res in grouped_results['S2A_10SEJ']]\n",
    "co_jpgs_diff = [(res[0], res[3]) for res in grouped_results['S2A_10SEJ']]\n",
    "\n",
    "images = {}\n",
    "with ThreadPoolExecutor(max_workers=3) as ex:\n",
    "    fs = list(ex.map(get_jpg, [co_jpgs_f1, co_jpgs_f2, co_jpgs_diff]))\n",
    "\n",
    "f, ax = plt.subplots(1,3, figsize=(18, 18))\n",
    "i = 0\n",
    "for j in sorted(images.keys()):\n",
    "    ax[i].set_title(j)\n",
    "    ax[i].imshow(images[j])\n",
    "    i = i+1\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexec.plot(dst=fexec.executor_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(filename=f'{fexec.executor_id}_histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3client = boto3.client('s3')\n",
    "total_sz = 0\n",
    "\n",
    "for scenes in [scenes_f1_all, scenes_f2_all]:\n",
    "    for scene in scenes:\n",
    "        for band in scene:\n",
    "            bucket, key = band.split('/', 1)\n",
    "            meta = s3client.head_object(Bucket=bucket, Key=key)\n",
    "            total_sz += int(meta['ResponseMetadata']['HTTPHeaders']['content-length'])\n",
    "\n",
    "stats = [f.stats for f in fexec.futures]\n",
    "mean_exec_time = np.mean([stat['worker_func_exec_time'] for stat in stats])\n",
    "throughput = (total_sz / 1_000_000_000) / mean_exec_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Procesed {round(total_sz / 1_000_000_000, 2)} GB in {round(mean_exec_time, 2)} s => {round(throughput, 2)} GB/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbxms_price = 0.0000000167\n",
    "sum_total_time = sum([stat['worker_exec_time'] for stat in stats]) * 1000\n",
    "price = gbxms_price * sum_total_time * 1  # Price GB/ms * sum of times in ms * 1 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Experiment total price is {round(price, 3)} USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
